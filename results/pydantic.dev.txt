=== https://pydantic.dev ===
Introducing PydanticAIPydanticAI is an agent framework to make it less painful to build production grade applications with generative AI.Learn moreLearn more>pip install pydantic-ai
Introducing PydanticAIPydanticAI is an agent framework to make it less painful to build production grade applications with generative AI.Learn moreLearn more>pip install pydantic-ai
Introducing PydanticAIPydanticAI is an agent framework to make it less painful to build production grade applications with generative AI.Learn moreLearn more
Introducing PydanticAIPydanticAI is an agent framework to make it less painful to build production grade applications with generative AI.Learn moreLearn more
PydanticAI is an agent framework to make it less painful to build production grade applications with generative AI.
Learn more
Learn more
>pip install pydantic-ai
>pip install pydantic-ai
>pip install pydantic-ai
Respected builders of open source, for Python & beyondPydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
Respected builders of open source, for Python & beyondPydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
Respected builders of open source, for Python & beyondPydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
Respected builders of open source, for Python & beyondPydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
Respected builders of open source, for Python & beyondPydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
Pydantic is built on the pillars of open source: transparency, collaboration and excellence. Our origins inform every product we craft. Whether it’s a community project or enterprise solution, developer experience is our cornerstone.
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}pydanticNext SlideNext SlideNext SlideNext SlidepydanticThe most popular data validation library for PythonPydanticAIAgent Framework / shim to use Pydantic with LLMsjiterThe fast, iterable JSON parserarqFast job queuing and RPC in PythonspeedateDate, time and duration parsing for Rust
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}pydanticNext SlideNext SlideNext SlideNext SlidepydanticThe most popular data validation library for PythonPydanticAIAgent Framework / shim to use Pydantic with LLMsjiterThe fast, iterable JSON parserarqFast job queuing and RPC in PythonspeedateDate, time and duration parsing for Rust
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}pydanticNext SlideNext SlideNext SlideNext Slide
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}pydanticNext SlideNext SlideNext SlideNext Slide
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.textusespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)
fromdatetimeimportdatetimefromtypingimportTuplefrompydanticimportBaseModelclassDelivery(BaseModel):
timestamp: datetime
dimensions:Tuple[int,int]
m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10','20'])print(repr(m.timestamp))#> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))print(m.dimensions)#> (10, 20)
frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.
frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.
frompydantic_aiimportAgent
agent = Agent('openai:gpt-4o',
system_prompt='Be concise, reply with one sentence.',
)
result = agent.run_sync('Where does `hello world` come from?')print(result.data)#> The first known use of "hello, world" was#> in a 1974 textbook about the C language.
usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}
usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}
usejiter::JsonValue;fnmain() {letjson_data=r#"
{
\"name\": \"John Doe\",
\"age\": 43,
\"phones\": [
\"+44 1234567\",
\"+44 2345678\"
]
}"#;letjson_value= JsonValue::parse(json_data.as_bytes(),true).unwrap();
}
importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.text
importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.text
importasynciofromarqimportcreate_poolfromarq.connectionsimportRedisSettingsfromhttpximportAsyncClientasyncdefmain():
redis =awaitcreate_pool(RedisSettings())forurlin('https://facebook.com','https://microsoft.com','https://github.com'):awaitredis.enqueue_job('download_content', url)asyncdefdownload_content(ctx, url):asyncwithAsyncClient()asclient:
response =awaitclient.get(url)returnresponse.text
usespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
usespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
usespeedate::{DateTime, Date, Time};fnmain() {letdt= DateTime::parse_str("2022-01-01T12:13:14Z").unwrap();assert_eq!(
dt,
DateTime {
date: Date {
year:2022,
month:1,
day:1,
},
time: Time {
hour:12,
minute:13,
second:14,
nanosecond:0,
},
},
);
}
pydanticNext SlideNext SlideNext SlideNext Slide
pydantic
Next Slide
Next Slide
Next Slide
Next Slide
Next Slide
Next Slide
Next Slide
Next Slide
pydanticThe most popular data validation library for PythonPydanticAIAgent Framework / shim to use Pydantic with LLMsjiterThe fast, iterable JSON parserarqFast job queuing and RPC in PythonspeedateDate, time and duration parsing for Rust
pydanticThe most popular data validation library for Python
The most popular data validation library for Python
PydanticAIAgent Framework / shim to use Pydantic with LLMs
Agent Framework / shim to use Pydantic with LLMs
jiterThe fast, iterable JSON parser
The fast, iterable JSON parser
arqFast job queuing and RPC in Python
Fast job queuing and RPC in Python
speedateDate, time and duration parsing for Rust
Date, time and duration parsing for Rust
The Pydantic Library is used and trusted by some of the biggest organizations in the world — and millions of individual developers, too.
The Pydantic Library is used and trusted by some of the biggest organizations in the world — and millions of individual developers, too.
The Pydantic Library is used and trusted by some of the biggest organizations in the world — and millions of individual developers, too.
The Pydantic Library is used and trusted by some of the biggest organizations in the world — and millions of individual developers, too.
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIPydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI StudioWe use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIIntegrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadogIf you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIPydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI StudioWe use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIIntegrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadogIf you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIPydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI StudioWe use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIIntegrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadogIf you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIPydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI StudioWe use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAIIntegrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadogIf you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.
Atty EletiMember of Technical Staff atOpenAI
Atty EletiMember of Technical Staff atOpenAI
Pydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI Studio
Pydantic is incredibly powerful and a must use tool for AI engineers.Logan KilpatrickLead product forGoogle AI Studio
Pydantic is incredibly powerful and a must use tool for AI engineers.
Logan KilpatrickLead product forGoogle AI Studio
Logan KilpatrickLead product forGoogle AI Studio
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.Atty EletiMember of Technical Staff atOpenAI
We use Pydantic across key parts of our research and products, and it has accelerated our work considerably.
Atty EletiMember of Technical Staff atOpenAI
Atty EletiMember of Technical Staff atOpenAI
Integrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadog
Integrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.Ofek LevSenior Software Engineer atDatadog
Integrations that run on the Datadog Agent use Pydantic models that are generated from an OpenAPI spec to validate configuration which has drastically reduced customer confusion and support cases that we have to triage.
Ofek LevSenior Software Engineer atDatadog
Ofek LevSenior Software Engineer atDatadog
If you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
If you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.Sebastián Ramírezcreator ofFastAPI
If you're not using Python yet, you should. If you're not using Pydantic yet with Python, you should. Pydantic is the data backbone of FastAPI, but even if you don't use FastAPI, Pydantic is extremely useful. There's always data, and handling data with Pydantic is several times more efficient and safer than without it and much more enjoyable.
Sebastián Ramírezcreator ofFastAPI
Sebastián Ramírezcreator ofFastAPI
OUR MISSIONDriven by curiosity, frustration and coffeeLearn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.Our articles/LogfirePydanticAI MCP Support & Logfire MCP Server AnnouncementSamuel Colvin2025/03/20/LogfirePydantic Logfire Rust SDK AnnouncementSamuel Colvin2025/03/19
OUR MISSIONDriven by curiosity, frustration and coffeeLearn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.Our articles/LogfirePydanticAI MCP Support & Logfire MCP Server AnnouncementSamuel Colvin2025/03/20/LogfirePydantic Logfire Rust SDK AnnouncementSamuel Colvin2025/03/19
OUR MISSIONDriven by curiosity, frustration and coffeeLearn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.Our articles/LogfirePydanticAI MCP Support & Logfire MCP Server AnnouncementSamuel Colvin2025/03/20/LogfirePydantic Logfire Rust SDK AnnouncementSamuel Colvin2025/03/19
OUR MISSIONDriven by curiosity, frustration and coffee
OUR MISSIONDriven by curiosity, frustration and coffee
OUR MISSION
Learn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.
Learn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.
Learn more about the creators of Pydantic, our mission and open source ethos. And see how you can get involved.
Our articles
/LogfirePydanticAI MCP Support & Logfire MCP Server AnnouncementSamuel Colvin2025/03/20/LogfirePydantic Logfire Rust SDK AnnouncementSamuel Colvin2025/03/19
/LogfirePydanticAI MCP Support & Logfire MCP Server Announcement
/Logfire
Samuel Colvin2025/03/20
Samuel Colvin
Samuel Colvin
Samuel Colvin
2025/03/20
/LogfirePydantic Logfire Rust SDK Announcement
/Logfire
Samuel Colvin2025/03/19
Samuel Colvin
Samuel Colvin
Samuel Colvin
2025/03/19

=== https://logfire.pydantic.dev/docs/ ===
Skip to content
Getting Started¶About Logfire¶From the team behindPydantic,Logfireis a new type of observability platform built on
the same belief as our open source library — that the most powerful tools can be easy to use.Logfireis built on OpenTelemetry, and supports monitoring your application fromany language,
with particularly great support for Python!Read more.Overview¶This page is a quick walk-through for setting up a Python app:Set up LogfireInstall the SDKInstrument your projectSet up Logfire¶Log into LogfireFollow the prompts to create your accountFrom your Organisation, clickNew projectto create your first projectThe first time you useLogfirein a new environment, you'll need to set up a project. ALogfireproject is a namespace for organizing your data. All data sent toLogfiremust be associated with a project.You can also create a project via CLI...Check theSDK CLI documentationfor more information on how to create a project via CLI.Install the SDK¶In the terminal, install theLogfireSDK (Software Developer Kit):pipuvpoetrycondapipinstalllogfireuvaddlogfirepoetryaddlogfirecondainstall-cconda-forgelogfireOnce installed, try it out!logfire-hNext, authenticate your local environment:logfireauthUpon successful authentication, credentials are stored in~/.logfire/default.toml.Instrument your project¶DevelopmentProductionDevelopment setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewProduction setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewNext steps¶Ready to keep going?Read aboutConceptsComplete theOnboarding ChecklistMore topics to explore...Logfire's real power comes fromintegrations with many popular librariesAs well as spans, you canuse Logfire to record metricsLogfire doesn't just work with Python,read more about Language supportCompliance requirements (e.g. SOC2)?See Logfire's certificationsBack to top
Getting Started¶About Logfire¶From the team behindPydantic,Logfireis a new type of observability platform built on
the same belief as our open source library — that the most powerful tools can be easy to use.Logfireis built on OpenTelemetry, and supports monitoring your application fromany language,
with particularly great support for Python!Read more.Overview¶This page is a quick walk-through for setting up a Python app:Set up LogfireInstall the SDKInstrument your projectSet up Logfire¶Log into LogfireFollow the prompts to create your accountFrom your Organisation, clickNew projectto create your first projectThe first time you useLogfirein a new environment, you'll need to set up a project. ALogfireproject is a namespace for organizing your data. All data sent toLogfiremust be associated with a project.You can also create a project via CLI...Check theSDK CLI documentationfor more information on how to create a project via CLI.Install the SDK¶In the terminal, install theLogfireSDK (Software Developer Kit):pipuvpoetrycondapipinstalllogfireuvaddlogfirepoetryaddlogfirecondainstall-cconda-forgelogfireOnce installed, try it out!logfire-hNext, authenticate your local environment:logfireauthUpon successful authentication, credentials are stored in~/.logfire/default.toml.Instrument your project¶DevelopmentProductionDevelopment setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewProduction setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewNext steps¶Ready to keep going?Read aboutConceptsComplete theOnboarding ChecklistMore topics to explore...Logfire's real power comes fromintegrations with many popular librariesAs well as spans, you canuse Logfire to record metricsLogfire doesn't just work with Python,read more about Language supportCompliance requirements (e.g. SOC2)?See Logfire's certifications
Getting Started¶About Logfire¶From the team behindPydantic,Logfireis a new type of observability platform built on
the same belief as our open source library — that the most powerful tools can be easy to use.Logfireis built on OpenTelemetry, and supports monitoring your application fromany language,
with particularly great support for Python!Read more.Overview¶This page is a quick walk-through for setting up a Python app:Set up LogfireInstall the SDKInstrument your projectSet up Logfire¶Log into LogfireFollow the prompts to create your accountFrom your Organisation, clickNew projectto create your first projectThe first time you useLogfirein a new environment, you'll need to set up a project. ALogfireproject is a namespace for organizing your data. All data sent toLogfiremust be associated with a project.You can also create a project via CLI...Check theSDK CLI documentationfor more information on how to create a project via CLI.Install the SDK¶In the terminal, install theLogfireSDK (Software Developer Kit):pipuvpoetrycondapipinstalllogfireuvaddlogfirepoetryaddlogfirecondainstall-cconda-forgelogfireOnce installed, try it out!logfire-hNext, authenticate your local environment:logfireauthUpon successful authentication, credentials are stored in~/.logfire/default.toml.Instrument your project¶DevelopmentProductionDevelopment setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewProduction setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewNext steps¶Ready to keep going?Read aboutConceptsComplete theOnboarding ChecklistMore topics to explore...Logfire's real power comes fromintegrations with many popular librariesAs well as spans, you canuse Logfire to record metricsLogfire doesn't just work with Python,read more about Language supportCompliance requirements (e.g. SOC2)?See Logfire's certifications
From the team behindPydantic,Logfireis a new type of observability platform built on
the same belief as our open source library — that the most powerful tools can be easy to use.
Logfireis built on OpenTelemetry, and supports monitoring your application fromany language,
with particularly great support for Python!Read more.
This page is a quick walk-through for setting up a Python app:
The first time you useLogfirein a new environment, you'll need to set up a project. ALogfireproject is a namespace for organizing your data. All data sent toLogfiremust be associated with a project.
The first time you useLogfirein a new environment, you'll need to set up a project. ALogfireproject is a namespace for organizing your data. All data sent toLogfiremust be associated with a project.
Check theSDK CLI documentationfor more information on how to create a project via CLI.
pipuvpoetrycondapipinstalllogfireuvaddlogfirepoetryaddlogfirecondainstall-cconda-forgelogfire
pipuvpoetryconda
pipinstalllogfireuvaddlogfirepoetryaddlogfirecondainstall-cconda-forgelogfire
pipinstalllogfire
pipinstalllogfire
uvaddlogfire
uvaddlogfire
poetryaddlogfire
poetryaddlogfire
condainstall-cconda-forgelogfire
condainstall-cconda-forgelogfire
logfire-h
logfireauth
Upon successful authentication, credentials are stored in~/.logfire/default.toml.
Upon successful authentication, credentials are stored in~/.logfire/default.toml.
DevelopmentProductionDevelopment setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewProduction setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveview
DevelopmentProduction
Development setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveviewProduction setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveview
Development setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.Set your projectin the terminal:logfireprojectsuse<first-project>Run this command from the root directory of your app, e.g.~/projects/first-projectWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveview
Development setupDuring development, we recommend using the CLI to configure Logfire.
You can also use awrite token.
Development setup
During development, we recommend using the CLI to configure Logfire.
You can also use awrite token.
in the terminal:logfireprojectsuse<first-project>
Run this command from the root directory of your app, e.g.~/projects/first-project
Run this command from the root directory of your app, e.g.~/projects/first-project
hello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!
Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.
Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.
Production setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.Generate a new write token in theLogfireplatformGo to ProjectSettingsWrite TokensFollow the prompts to create a new tokenConfigure yourLogfireenvironmentIn the terminal:exportLOGFIRE_TOKEN=<your-write-token>Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.jsonWrite some basic logs in your Python apphello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!Theconfigure()method should be called once before logging to initializeLogfire.This will logHello world!withinfolevel.Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.See your logs in theLiveview
Production setupIn production, we recommend you provide your write token to the Logfire SDK via environment variables.
Production setup
In production, we recommend you provide your write token to the Logfire SDK via environment variables.
Generate a new write token in theLogfireplatform
Configure yourLogfireenvironment
In the terminal:exportLOGFIRE_TOKEN=<your-write-token>
Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.json
Running this command stores a Write Token used by the SDK to send data to a file in the current directory, at.logfire/logfire_credentials.json
hello_world.pyimportlogfirelogfire.configure()# (1)!logfire.info('Hello,{name}!',name='world')# (2)!
Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.
Otherlog levelsare also available to use, includingtrace,debug,notice,warn,error, andfatal.
Ready to keep going?
More topics to explore...

